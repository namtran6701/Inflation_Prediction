{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we apply machine learning methods to predict Consumer Price Index. \n",
    "\n",
    "After obtaining the predicted CPI, we would then calculate monthly and yearly inflation.\n",
    "\n",
    "After carefully considering the underlying structure of the data, we decided to build models using the period 2010-2020\n",
    "\n",
    "- 2010 - 2017 as training data\n",
    "\n",
    "- 2017 - 2019 as validation data\n",
    "\n",
    "- 2019 - 2020 as test data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Preprocessing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Label Decomposition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "import seaborn as sns\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "# from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "\n",
    "df = pd.read_csv('cpi.csv', parse_dates= [['Year', 'Month']], index_col= 'Year_Month')\n",
    "\n",
    "# get data from 2010 to 2020\n",
    "df = df.loc['2010-01-01':'2019-12-31']\n",
    "\n",
    "# Set the monthly frequency for the data\n",
    "\n",
    "df.index.freq = 'MS'\n",
    "\n",
    "# Change the index name to 'Date'\n",
    "df.index.name = 'Date'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize monthly and yearly inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1-Month % Change'].plot()\n",
    "plt.title('1-month inflation rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['12-Month % Change'].plot()\n",
    "plt.title('12-month inflation rate')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current main focus is the CPI index, so let's decompose this feature first.\n",
    "- First, decompose the CPI column into trend, seasonal, and residual components using additive method. \n",
    "- Second, apply multiplicative method\n",
    "- Since we may apply detrending method as a way to make the data stationary, we will be using backward looking moving average in order to smooth out the noise (instead of the center moving average) and reduce the number of future observation lost. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CPI'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Additive decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additive_decomposed = seasonal_decompose(df['CPI'], model='additive',two_sided= False, period= 6)\n",
    "\n",
    "# Plot the original data, trend, seasonal, and residual components\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# Original data\n",
    "ax1.plot(df['CPI'])\n",
    "ax1.set_title('Original Data')\n",
    "ax1.grid()\n",
    "\n",
    "# Trend component\n",
    "ax2.plot(additive_decomposed.trend)\n",
    "ax2.set_title('Trend Component')\n",
    "ax2.grid()\n",
    "\n",
    "# Seasonal component\n",
    "ax3.plot(additive_decomposed.seasonal)\n",
    "ax3.set_title('Seasonal Component')\n",
    "ax3.grid()\n",
    "\n",
    "# Residual component\n",
    "ax4.plot(additive_decomposed.resid)\n",
    "ax4.set_title('Residual Component')\n",
    "ax4.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A statistical look into the seasonal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additive_decomposed.seasonal.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Multiplicative Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicative_decomposed = seasonal_decompose(df['CPI'], model='multiplicative',two_sided= False, period= 6)\n",
    "\n",
    "# Plot the original data, trend, seasonal, and residual components\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# Original data\n",
    "ax1.plot(df['CPI'])\n",
    "ax1.set_title('Original Data')\n",
    "ax1.grid()\n",
    "\n",
    "# Trend component\n",
    "ax2.plot(multiplicative_decomposed.trend)\n",
    "ax2.set_title('Trend Component')\n",
    "ax2.grid()\n",
    "\n",
    "# Seasonal component\n",
    "ax3.plot(multiplicative_decomposed.seasonal)\n",
    "ax3.set_title('Seasonal Component')\n",
    "ax3.grid()\n",
    "\n",
    "# Residual component\n",
    "ax4.plot(multiplicative_decomposed.resid)\n",
    "ax4.set_title('Residual Component')\n",
    "ax4.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Decomposition Conclusion\n",
    "\n",
    "- After trying multiple periods/frequencies, we decided to use a period of 6 to decompose the CPI index as it results the perfect seasonal component. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both multiplicative and additive decomposition show that the trend component is the most important component in the CPI index. \n",
    "\n",
    "However, residuals in the multiplicative decomposition is more stable than in additive approach, so we should move forward with mulitplicative approach. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain statistical attributes of the trend component\n",
    "additive_decomposed.trend.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the series has a linear trend, it is definitely not stationary. Thus, we should attempt to make it stationary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can address how statistical properties of a series change over time by visualizing. This would help us check the structural break and heteroscedasticity issue. \n",
    "- The rolling window size is 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fucntion to plot rolling variance and rolling mean\n",
    "def rolling_statistics(timeseries, custom_name, window_size=12):\n",
    "    # Determine rolling statistics\n",
    "    rolling_mean = timeseries.rolling(window=window_size).mean()\n",
    "    rolling_std = timeseries.rolling(window=window_size).std()\n",
    "\n",
    "    # Plot rolling statistics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(rolling_mean, color='black', label='Rolling Mean')\n",
    "    plt.plot(rolling_std, color='red', label='Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation of ' + custom_name)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Label Diffencing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's work on differncing the data to see if the process can make the data more stationay. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 First Order Differencing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first order differencing, we would subtract the immediate previous value from the current value to obtain the difference between two consecutive periods. \n",
    "\n",
    "First-Order Differencing = Value at time t - Value at time t-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data = df['CPI'].diff().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data.plot()\n",
    "plt.title('First - Order Differenced Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_statistics(diff_data, 'First - Order Differenced Data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Second Order Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_order_diff = diff_data.diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_order_diff.plot()\n",
    "plt.title('Second - Order Differenced Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_statistics(second_order_diff, 'Second - Order Differenced Data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Label Detrending"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The method for smoothing data used in this project is backward moving average.\n",
    "\n",
    "- Detrended data is computed by subtracting the trend values from the actual values. \n",
    "\n",
    "- Since we use a period of 6 to smooth out the data, the function will use a centered moving average witha window size of 6 to smooth the trend component (6 periods prior to the current value).\n",
    "\n",
    "- As a result, we would lose 6 observations in using label detrending, compared to only 1 in first-order differencing, and 2 in second-order differencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I extract the trend component from the multiplicative decomposition. Trend values from either multiplicative or additive decompositions are identical.\n",
    "trend = multiplicative_decomposed.trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detrend = df['CPI']- trend\n",
    "\n",
    "detrend.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detrend.plot()\n",
    "plt.title('Detrended Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_statistics(detrend, 'Detrended Data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Differencing and Detrending Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean and variance of these transformed data are not constant over time. Between the 3 transformation method, the second order differencing appear to be the most stationary. Therefore, we would move forward with second order differencing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Label Transformation (Make it stationary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to calculate the ADF test and print out the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationary_test(input):\n",
    "\n",
    "    result = adfuller(input)\n",
    "    print('ADF Statistic:', result[0])\n",
    "    print('p-value:', result[1])\n",
    "    print('Critical Values:', result[4])\n",
    "\n",
    "    # Reject the null hypothesis if the p-value is below the chosen significance level\n",
    "    if result[1] < 0.05:\n",
    "        print(\"The data is STATIONARY.\")\n",
    "    else:\n",
    "        print(\"The data is NOT STATIONARY.\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the ADF test, let's use the non parametric KPSS test to confirm the stationarity of the data. If KPSS's result contradict conclusion from ADF, we need to investigate further. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Augemnted Dickey-Fuller Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To statistically verify if the data is stationary or not, we would deploy ADF test. \n",
    "\n",
    "- Null hypothesis: The time series contains a unit root and is non-stationary\n",
    "\n",
    "- Alternative hypothesis is that the time series is stationary. \n",
    "\n",
    "To confirm that the data is stationary, we need a p-value that is lower than the significance level in order to reject the null hypothesis, and the critical values should be greater greater than the ADF statistics.\n",
    "\n",
    "- The significance level chosen is 0.05. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ADF on the orignal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_test(df['CPI'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ADF on the second order differenced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_test(second_order_diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Non-parametric KPSS test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Null hypothesis: The time series is stationary (no unit root)\n",
    "\n",
    "- Alternative hypothesis: The time series is stastionary (it has a unit root)\n",
    "\n",
    "KPSS' test statistic is compared to the relevant critical values. If the test statistic is greater than the cirtical value at a chosen level of significance, we reject the null hypothesis  and conclude that the series is non-stationary with a unit root. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to perform the kpss test.\n",
    "def kpss_test(input):\n",
    "        result = kpss(input)\n",
    "        print('KPSS Statistic:', result[0])\n",
    "        print('p-value:', result[1])\n",
    "        print('Critical Values:', result[3])\n",
    "    \n",
    "        # Reject the null hypothesis if the p-value is below the chosen significance level\n",
    "        if result[1] < 0.05:\n",
    "            print(\"The data is NOT STATIONARY.\")\n",
    "        else:\n",
    "            print(\"The data is STATIONARY.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. KPSS test on the orignal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpss_test(df['CPI'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. KPSS test on the second-order differenced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpss_test(second_order_diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most critical values across level of significance are well beyond the test statistic. This supports the Null hypothesis that the series is stationary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ADF and KPSS test conclusion "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second-order differencing data is found to be stationary by using ADF and KPSS test, while the original data is not stationary (as expected). Results from both test are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot to compare the distribution of the detrended data and the first-order differenced data\n",
    "def cus_boxplot(data1, title1):\n",
    "    fig, ax1 = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    sns.boxplot(data1, ax=ax1)\n",
    "    ax1.set_title(title1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus_boxplot(second_order_diff, 'Second-Order Differenced Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data statisitcal summary\n",
    "\n",
    "print('Second order difference data statistical summary:')\n",
    "second_order_diff.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 White Noise Check "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test, we would test the autocorrelation between the current value its 12 lags. If there exist a correlation between the current value and a number of its lags, then the series is not white noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to check if a pandas time series is a white noise. Import package for acirr_ljungbox test\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "def white_noise_test(input):\n",
    "    # Calculate the p-value of the autocorrelation\n",
    "    lags = 12\n",
    "    p_val_list = []\n",
    "    for i in range(1, lags):\n",
    "        result = acorr_ljungbox(input, lags= lags)\n",
    "        p_value = result.iloc[i-1,1]\n",
    "        p_val_list.append(p_value)\n",
    "    # check if all p_values in the list are below 0.05, then the time series is not a white noise\n",
    "    if all(i < 0.05 for i in p_val_list):\n",
    "        print('The time series is NOT a white noise.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_noise_test(second_order_diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the series illustrate a correlation between the current value and its lags, the data is thus not white noise. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lag Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the useful lag variables, we can use the autocorrelation function (ACF) and Partial Autocorrelation Function (PACF) plots."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between ACF and PACF is that ACF measures the total correlation between a time series and its lagged values, while PACF measures the direct correlation between a time series and its lagged values after removing the effect of the correlations with the intervening observations. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACF is primarily used to determine the MA component, while the PACF plot is used to determine the AR component.\n",
    "\n",
    "The shaded area is the signifiance level in the ACF and PACF plots. If a lag is above the shaded area, it is significantly correlated with the label. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Label's ACF and PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF plot\n",
    "plot_acf(second_order_diff, lags= 24, zero=False)\n",
    "plt.title('ACF Plot of Second-Order Differenced Data')\n",
    "plt.show()\n",
    "\n",
    "# PACF plot\n",
    "plot_pacf(second_order_diff, lags = 24, zero=False)\n",
    "plt.title('PACF Plot of Second-Order Differenced Data')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Lag Analysis Conclusion "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ACF plot shows that the label is correlated with its lagged values up to 3 periods.\n",
    "\n",
    "- Meanwhile, the PACF shows that the label is directly correlated with the first 4 lag values and lags of 9 and 22. We can't really be sure that lag 22 are really substantially significnnt as it shows on the graph due to the small size of the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, validation, and test sets\n",
    "\n",
    "train = second_order_diff.loc['2010-01-01':'2016-12-31']\n",
    "\n",
    "val = second_order_diff.loc['2017-01-01':'2018-12-31']\n",
    "\n",
    "test = second_order_diff.loc['2019-01-01':'2019-12-31']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Modeling 1 (Lag Predictors only)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Base model: ARIMA(1,2,1)\n",
    "\n",
    "- The ARIMA(p,d,q) model contains 3 main components: AR, I (differencing), and MA.\n",
    "\n",
    "- After carefully taking into consideration, second-order differencing seems to be the best way to make the data stationary so decided to use it as the base model for comparision purpose.\n",
    "\n",
    "- The model takes into account 1 lagged values, 1 lagged errors, and 2 order differencing. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Model Executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit an ARIMA(1,2,1) model to the training set\n",
    "\n",
    "#! Here we set I = 0 since we have manually differenced the data\n",
    "base_model = ARIMA(train, order=(1,0,1)).fit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The lag of 1 component is found statistically insignificant since it has a very high p-value. Meanwhile, the AR component, which is the error term of the 1st lag. \n",
    "\n",
    "- The negative figure for skew and kurtosis also tell us about the distribution of the model's residuals as they are found to be skewed to the left and contain a fat tail. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Predicting the Validation set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if possible, please repeat the mean, standard deviation of the label here (2nd-order differenced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast values for the validation set\n",
    "validation_forecast = base_model.forecast(steps=len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecasted values and the actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(val, label='Actual')\n",
    "plt.plot(validation_forecast, label='Forecast')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('ARIMA(1,0,1)')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae = np.mean(np.abs(validation_forecast - val))\n",
    "mse = np.mean((validation_forecast - val)**2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"MAE: {mae:.2f}, MSE: {mse:.2f}, RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ARIMA with more ARs and MAs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From ACF and PACF results above, we were able to identify lags that are significantly correlated with the label, \n",
    "\n",
    "- ACF's result is helpful in determining AR components, while PACF's helps determine MA components"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs earlier, we would sequtially add MA and AR component to the model and observe how AIC and BIC change.\n",
    "\n",
    "- A lower BIC and AIC are preferred. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a for loop to loop through the potential models and view the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = [2,3]\n",
    "ma = [1,2,3,4]\n",
    "\n",
    "for i in ma:\n",
    "\n",
    "    for j in ar:\n",
    "        \n",
    "        # train and fit the model\n",
    "        \n",
    "        model = ARIMA(train, order=(j,0,i)).fit(method_kwargs={'maxiter': 100})\n",
    "        \n",
    "        validation_forecast = model.forecast(steps=len(val))\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        \n",
    "        mae = np.mean(np.abs(validation_forecast - val))\n",
    "        \n",
    "        mse = np.mean((validation_forecast - val)**2)\n",
    "        \n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Plot the forecasted values and the actual values\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        plt.plot(val, label='Actual')\n",
    "        \n",
    "        plt.plot(validation_forecast, label='Forecast')\n",
    "        \n",
    "        plt.legend(loc='upper left')\n",
    "        \n",
    "        plt.title(f'ARIMA({j},0,{i})')\n",
    "        \n",
    "        plt.text(0.88, 0.98, f'MAE: {mae:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}', \n",
    "                 transform=plt.gca().transAxes, verticalalignment='top')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        # Attacht the model's summary right below the graph\n",
    "\n",
    "        print(model.summary())\n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ARIMA Model's Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The best ARIMA model so far is ARIMA(3,0,3). For some other ARIMA model versions, the maximum likelihood optimization method fails to converge. Therefore, it leads to poor predictions, as we can see there is a horizontal line for some ARIMA model's predictions, which is completely different than the ARIMA(3,0,3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Engineearing Models With Ext Components "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing Predictors "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import and format data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import data with external predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = pd.read_csv('full_data.csv', index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some basic infor from the data \n",
    "predictors.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the date consistent with the CPI data\n",
    "predictors = predictors.loc[:'2019-12-31']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Apply first order differencing on predictors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since we have taken differencing on CPI, it makes sense to take transform predictors to at least a first order differencing as well. Also, we would like to see how the change in these variables affect movement in the label.\n",
    "- Also, as I have attempted to use the original data, the multicollinarity issue was so serious that we can't move forward with it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply diff on all columns in predictors \n",
    "predictors = predictors.diff().dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Normalize Predictors "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Remove Outliers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All predictors are deemed to be equally important but they appear to be on different scale, thus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data by plotting their distributions and boxplots\n",
    "# sns.pairplot(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all outliers in the predictors file using IQR method\n",
    "def replace_outliers(data):\n",
    "    for col in data.columns:\n",
    "        q1 = data[col].quantile(0.25)\n",
    "        q3 = data[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        \n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        \n",
    "        data[col] = np.where(data[col] < lower_bound, lower_bound, data[col])\n",
    "        data[col] = np.where(data[col] > upper_bound, upper_bound, data[col])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_predictors = replace_outliers(predictors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Normalize predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize clean predictors data using min-max scaler, and convert it to a dataframe\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "clean_predictors = scaler.fit_transform(clean_predictors)\n",
    "clean_predictors = pd.DataFrame(clean_predictors, columns=predictors.columns, index=predictors.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Merge with the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the clean predictors data with the CPI data\n",
    "full_data = pd.merge(second_order_diff, clean_predictors, left_index=True, right_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix of full_data and visualize it using heatmap\n",
    "corr_matrix = full_data.corr().round(2)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Correlation Analysis Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most features are moderately or weakly correlated with CPI. In economic sense, they should have a strong correlation with the label, however, since we have differenced both label and features, the strong correlation no longer holds. \n",
    "\n",
    "- Though some features like Money_Stock (M2 money supply) and FedSurDef are found to have a small correlation with the label, it might still be useful based on our domain knowledge. \n",
    " \n",
    "- In addition, since correlation measures only linear relationships, non-linear relationships between predictors and lable can still be significant and useful for prediction and they won't be captured by correlation coefficients. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection with Lasso Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Though the current set of variables look good. Next, we apply Lasso Regression to filter the number of predictors even further in order to retain the most important variables only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "# split the data \n",
    "target = 'CPI'\n",
    "\n",
    "train = full_data.loc['2010-01-01':'2016-12-31']\n",
    "\n",
    "val = full_data.loc['2017-01-01':'2018-12-31']\n",
    "\n",
    "test = full_data.loc['2019-01-01':'2019-12-31']\n",
    "\n",
    "x_train = train.drop(columns = [target])\n",
    "\n",
    "y_train = train[target]\n",
    "\n",
    "x_val = val.drop(columns = [target])\n",
    "\n",
    "y_val = val[target]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best alpha as performed below is the one that provides the optimal balance between fitting the data and preventing overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit a lasso regression with cross validation to find the best alpha\n",
    "model = LassoCV(alphas = None, cv = 3, random_state=123).fit(x_train, y_train)\n",
    "\n",
    "best_alpha = model.alpha_\n",
    "\n",
    "print(f\"Best alpha: {best_alpha:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Though we have found the best alpha, we are unable to apply it to the lasso regresion since it would only keep Crude oil as the sole predictor for the model. \n",
    "\n",
    "- Therfore, we reduce alpha to 0.01, while maintaining the same RMSE but it include more predictors for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit the model with the best alpha\n",
    "final_lasso = Lasso(alpha=0.01, random_state=123).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model performance on the validation set \n",
    "val_predictions = final_lasso.predict(x_val)\n",
    "val_mse = mean_squared_error(y_val, val_predictions)\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "print(f'Validation RMSE: {val_rmse:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insepct the coefficients to see which predictors were retained in the model \n",
    "coef_df = pd.DataFrame({'Feature': x_train.columns, 'Coefficient': final_lasso.coef_})\n",
    "coef_df = coef_df.sort_values(by='Coefficient', ascending=False)\n",
    "# print Feature from coef_df where Coefficient is different from 0\n",
    "\n",
    "print('Here is the list of predictors that were retained in the lasso regression using alpha = 0.01')\n",
    "\n",
    "coef_df[coef_df['Coefficient'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a vector names for these retained variables. \n",
    "selected_predictors = coef_df[coef_df['Coefficient'] != 0]['Feature'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for random forest regression \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a base random forest regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base = RandomForestRegressor(random_state=123)\n",
    "\n",
    "# Train the base model \n",
    "rf_base.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameter search space for grid search or random search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search space\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [10, 20, 30, 50, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chooose a search method (GridSearchCV or RandomizedSearchCV) and fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf_base, \n",
    "    param_grid=param_grid, \n",
    "    cv=3, \n",
    "    n_jobs=-1, \n",
    "    verbose=2)\n",
    "\n",
    "# Random search\n",
    "# n_iter: Number of random parameter combinations to try\n",
    "random_search = RandomizedSearchCV(estimator=rf_base, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=100, \n",
    "    cv=5, \n",
    "    n_jobs=-1, \n",
    "    verbose=2, \n",
    "    random_state=123)\n",
    "\n",
    "# Fit the search object, here we can use either random search or grid searchq\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best hyperparameters from the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_params = grid_search.best_params_\n",
    "\n",
    "random_search_params = random_search.best_params_\n",
    "\n",
    "print(f'Grid Search Best Hyperparameters: {best_hyperparameters}')\n",
    "\n",
    "print(f'Random Search Best Hyperparameters: {random_search_params}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both GridSearchCV and RandomizedSearchCV returned the same best hyperparameters. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the random forest model with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the best hyperparameters\n",
    "best_rf_regressor = RandomForestRegressor(**grid_search_params, random_state=123)\n",
    "\n",
    "# Train the model \n",
    "best_rf_regressor.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predicitons and evaluate the model performance using RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = best_rf_regressor.predict(x_val)\n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "mae = np.mean(np.abs(y_pred - y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot y_val and y_pred on the same graph, but first, we need to add a time index to y_pred\n",
    "y_pred = pd.Series(y_pred, index=y_val.index)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_val, label='Actual')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Random Forest Regression')\n",
    "plt.text(0.88, 0.98, f'MAE: {mae:.2f}\\nMSE: {mse:.2f}\\nRMSE: {rmse:.2f}', \n",
    "                 transform=plt.gca().transAxes, verticalalignment='top')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ideas for tomorrow. \n",
    "\n",
    "- add lag as a variable to random forest, probably from ARIMA(3,0,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
